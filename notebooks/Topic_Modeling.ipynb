{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic\n",
    "\n",
    "https://maartengr.github.io/BERTopic/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40121 entries, 0 to 40120\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    40121 non-null  int64 \n",
      " 1   user_id     40121 non-null  int64 \n",
      " 2   user_name   40121 non-null  object\n",
      " 3   created_at  40121 non-null  object\n",
      " 4   full_text   40121 non-null  object\n",
      " 5   retweets    40121 non-null  int64 \n",
      " 6   favorite    40121 non-null  int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# read Data\n",
    "PATH_DATA = \"../data/final/tweets_66DaysofData.csv\"\n",
    "df = pd.read_csv(PATH_DATA)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- remove links in tweets\n",
    "- remove '#66DaysofData' -> no meaning, is in every tweet\n",
    "- remove '@KenJee_DS' -> no meaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df[\"full_text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40121"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove links\n",
    "def replace_links(df:pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Funciton to replace links\n",
    "    \"\"\"\n",
    "    link_re = re.compile('http://\\S+|https://\\S+')\n",
    "    str_global = ''\n",
    "\n",
    "    for x in range(len(df.iloc[:100,])):\n",
    "        str_ = df['full_text'][x]\n",
    "        re_ = re.sub(link_re, '', str_)\n",
    "        str_global += re_ + ' ' \n",
    "\n",
    "    return str_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no links\n",
    "docs_no_links = []\n",
    "link_re = re.compile('http://\\S+|https://\\S+')\n",
    "for doc in docs:\n",
    "    re_ = re.sub(link_re, '', doc)\n",
    "    docs_no_links.append(re_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '#66DaysofData'\n",
    "docs_no_hashtag = []\n",
    "hashtag_re = re.compile('#66[D,d]ays[O,o]f[D,d]ata')\n",
    "for doc in docs_no_links:\n",
    "    re_ = re.sub(hashtag_re, '', doc)\n",
    "    docs_no_hashtag.append(re_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# remove '@KenJee_DS'\\ndocs_no_mention = []\\nmention_re = re.compile('@KenJee_DS')\\nfor dco in docs_no_hashtag[:10]:\\n    print(doc)\\n    re_ = re.sub(mention_re, '', doc)\\n    print(re_)\\n    docs_no_mention.append(re_)\\n\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# remove '@KenJee_DS'\n",
    "docs_no_mention = []\n",
    "mention_re = re.compile('@KenJee_DS')\n",
    "for dco in docs_no_hashtag[:10]:\n",
    "    print(doc)\n",
    "    re_ = re.sub(mention_re, '', doc)\n",
    "    print(re_)\n",
    "    docs_no_mention.append(re_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_no_mention = []\n",
    "mention_re = re.compile('@KenJee_DS')\n",
    "for doc in docs_no_hashtag:\n",
    "    re_ = re.sub(mention_re, '', doc)\n",
    "    docs_no_mention.append(re_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' looking forward to ',\n",
       " 'Very excited to announce the  initiative that I am starting September 1! I encourage you to participate by spending at least 5 minutes learning data science for 66 days straight. All you have to do is tweet what you are working on each day! ',\n",
       " ' Looking fwd to ',\n",
       " 'Let‚Äôs start  ',\n",
       " ' count me in ',\n",
       " 'Excited to start  with . ',\n",
       " \" Very excited about ! I'm in \",\n",
       " 'Very proud to start ',\n",
       " 'Super Excited to start with  Challenge ! ',\n",
       " 'Day 1 of  Right now I‚Äôm studying Functional Programming. First Im understanding the Python language and then applying this concepts to data science cases.  ',\n",
       " '\\n\\nVery Excited to Learn and Start. \\n\\nRight Now for the Following 3 days I will be learning Python for Data Science and ML Course on Udemy. \\n\\nWish you all a Happy Journey into Data Science',\n",
       " \"Sorry, but I can't wait! so I'm starting today! :D  \",\n",
       " 'Bring on the challenge!\\n',\n",
       " ' This is great! I‚Äôm learning DS right now so this new series by Ken will be extremely beneficial for me. Right now I‚Äôm working on loops. \\n\\n',\n",
       " ' Great initiative Ken count me in ',\n",
       " \" I'm in for this \",\n",
       " ' Looking forward to this ',\n",
       " \" I'm in \",\n",
       " ' Started the  challenge. Completed the basics of Numpy today, and will be practising a few basic problems on W3schools.',\n",
       " ' Thanks ken...for sharing ...I will be participating in this actively üî•... ']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_no_mention[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs_no_mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>14730</td>\n",
       "      <td>-1_my_and_data_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1523</td>\n",
       "      <td>0_pandas_dataframes_dataframe_manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>687</td>\n",
       "      <td>1_tableau_dashboard_visualization_public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>444</td>\n",
       "      <td>2_sports_sportsanalytics_sportsscience_nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>439</td>\n",
       "      <td>3_excel_pivot_sheets_spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>434</td>\n",
       "      <td>10</td>\n",
       "      <td>434_source_researchers_3d_subnetworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>435</td>\n",
       "      <td>10</td>\n",
       "      <td>435_othersnow_kaggletps_resourcesive_notch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>436</td>\n",
       "      <td>10</td>\n",
       "      <td>436_sql_statement_select_capitalized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>437</td>\n",
       "      <td>10</td>\n",
       "      <td>437_adventofcode2020_memory_deep_epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>438</td>\n",
       "      <td>10</td>\n",
       "      <td>438_math_steady_parabola_graphing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                        Name\n",
       "0       -1  14730                           -1_my_and_data_to\n",
       "1        0   1523  0_pandas_dataframes_dataframe_manipulation\n",
       "2        1    687    1_tableau_dashboard_visualization_public\n",
       "3        2    444  2_sports_sportsanalytics_sportsscience_nba\n",
       "4        3    439           3_excel_pivot_sheets_spreadsheets\n",
       "..     ...    ...                                         ...\n",
       "435    434     10       434_source_researchers_3d_subnetworks\n",
       "436    435     10  435_othersnow_kaggletps_resourcesive_notch\n",
       "437    436     10        436_sql_statement_select_capitalized\n",
       "438    437     10      437_adventofcode2020_memory_deep_epoch\n",
       "439    438     10           438_math_steady_parabola_graphing\n",
       "\n",
       "[440 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pandas', 0.030089901526128556),\n",
       " ('dataframes', 0.009101151499279913),\n",
       " ('dataframe', 0.00894642367665506),\n",
       " ('manipulation', 0.005434391141161202),\n",
       " ('merging', 0.0051516301467771095),\n",
       " ('numpy', 0.0051007582629295075),\n",
       " ('indexing', 0.0049845891342558705),\n",
       " ('groupby', 0.004704560878679829),\n",
       " ('loc', 0.004472518600210009),\n",
       " ('columns', 0.004460440618053577)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking forward to</td>\n",
       "      <td>88</td>\n",
       "      <td>88_starting_excited_start_late</td>\n",
       "      <td>starting - excited - start - late - tomorrow -...</td>\n",
       "      <td>0.483574</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very excited to announce the  initiative that ...</td>\n",
       "      <td>37</td>\n",
       "      <td>37_challenge_journey_participate_excited</td>\n",
       "      <td>challenge - journey - participate - excited - ...</td>\n",
       "      <td>0.450561</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looking fwd to</td>\n",
       "      <td>16</td>\n",
       "      <td>16_r4_r3_packtpub_d42</td>\n",
       "      <td>r4 - r3 - packtpub - d42 - golf - r2 - d39 - 3...</td>\n",
       "      <td>0.518637</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let‚Äôs start</td>\n",
       "      <td>88</td>\n",
       "      <td>88_starting_excited_start_late</td>\n",
       "      <td>starting - excited - start - late - tomorrow -...</td>\n",
       "      <td>0.422216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count me in</td>\n",
       "      <td>88</td>\n",
       "      <td>88_starting_excited_start_late</td>\n",
       "      <td>starting - excited - start - late - tomorrow -...</td>\n",
       "      <td>0.447060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40116</th>\n",
       "      <td>Day 03 - SQL -- SQL Basic clauses -- SELECT, W...</td>\n",
       "      <td>248</td>\n",
       "      <td>248_order_group_select_where</td>\n",
       "      <td>order - group - select - where - syntax - clau...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40117</th>\n",
       "      <td>üèÜ Day7 of \\n\\n‚úÖ Today, I read the paper Attent...</td>\n",
       "      <td>81</td>\n",
       "      <td>81_clash_code_coding_errors</td>\n",
       "      <td>clash - code - coding - errors - checklist - f...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40118</th>\n",
       "      <td>Day 31 of  \\nOrganized my SQL code and synced ...</td>\n",
       "      <td>83</td>\n",
       "      <td>83_dashboard_amplitude_dashboards_dash</td>\n",
       "      <td>dashboard - amplitude - dashboards - dash - ou...</td>\n",
       "      <td>0.246693</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40119</th>\n",
       "      <td>Day43 of¬†.\\nPreparation of Japan statistical s...</td>\n",
       "      <td>291</td>\n",
       "      <td>291_society_japan_grade_preparation</td>\n",
       "      <td>society - japan - grade - preparation - certif...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40120</th>\n",
       "      <td>Day 21 of  R4!\\n\\n- An article from Abid Ali A...</td>\n",
       "      <td>357</td>\n",
       "      <td>357_gpt3_barousse_dataanalyst_luke</td>\n",
       "      <td>gpt3 - barousse - dataanalyst - luke - openai ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40121 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Document  Topic  \\\n",
       "0                                    looking forward to      88   \n",
       "1      Very excited to announce the  initiative that ...     37   \n",
       "2                                        Looking fwd to      16   \n",
       "3                                          Let‚Äôs start       88   \n",
       "4                                           count me in      88   \n",
       "...                                                  ...    ...   \n",
       "40116  Day 03 - SQL -- SQL Basic clauses -- SELECT, W...    248   \n",
       "40117  üèÜ Day7 of \\n\\n‚úÖ Today, I read the paper Attent...     81   \n",
       "40118  Day 31 of  \\nOrganized my SQL code and synced ...     83   \n",
       "40119  Day43 of¬†.\\nPreparation of Japan statistical s...    291   \n",
       "40120  Day 21 of  R4!\\n\\n- An article from Abid Ali A...    357   \n",
       "\n",
       "                                           Name  \\\n",
       "0                88_starting_excited_start_late   \n",
       "1      37_challenge_journey_participate_excited   \n",
       "2                         16_r4_r3_packtpub_d42   \n",
       "3                88_starting_excited_start_late   \n",
       "4                88_starting_excited_start_late   \n",
       "...                                         ...   \n",
       "40116              248_order_group_select_where   \n",
       "40117               81_clash_code_coding_errors   \n",
       "40118    83_dashboard_amplitude_dashboards_dash   \n",
       "40119       291_society_japan_grade_preparation   \n",
       "40120        357_gpt3_barousse_dataanalyst_luke   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "0      starting - excited - start - late - tomorrow -...     0.483574   \n",
       "1      challenge - journey - participate - excited - ...     0.450561   \n",
       "2      r4 - r3 - packtpub - d42 - golf - r2 - d39 - 3...     0.518637   \n",
       "3      starting - excited - start - late - tomorrow -...     0.422216   \n",
       "4      starting - excited - start - late - tomorrow -...     0.447060   \n",
       "...                                                  ...          ...   \n",
       "40116  order - group - select - where - syntax - clau...     1.000000   \n",
       "40117  clash - code - coding - errors - checklist - f...     1.000000   \n",
       "40118  dashboard - amplitude - dashboards - dash - ou...     0.246693   \n",
       "40119  society - japan - grade - preparation - certif...     1.000000   \n",
       "40120  gpt3 - barousse - dataanalyst - luke - openai ...     1.000000   \n",
       "\n",
       "       Representative_document  \n",
       "0                        False  \n",
       "1                         True  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "40116                     True  \n",
       "40117                    False  \n",
       "40118                    False  \n",
       "40119                    False  \n",
       "40120                    False  \n",
       "\n",
       "[40121 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_info(docs_no_mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_idx = df[df[\"user_name\"] == \"MarkusM99098101\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Learning DS since January, now committing to :...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_my_and_data_to</td>\n",
       "      <td>my - and - data - to - the - day - of - for - ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Day 1 of : Today I worked on my stock analysis...</td>\n",
       "      <td>191</td>\n",
       "      <td>191_trading_indicators_market_trade</td>\n",
       "      <td>trading - indicators - market - trade - system...</td>\n",
       "      <td>0.298689</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Day 2 of  : Today I made a lot of progress on ...</td>\n",
       "      <td>191</td>\n",
       "      <td>191_trading_indicators_market_trade</td>\n",
       "      <td>trading - indicators - market - trade - system...</td>\n",
       "      <td>0.292834</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Day 3 of  : Today I learned about and implemen...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_my_and_data_to</td>\n",
       "      <td>my - and - data - to - the - day - of - for - ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Day 4 of , made an account on HackerRank, did ...</td>\n",
       "      <td>305</td>\n",
       "      <td>305_hackerrank_codewars_productivity_sql</td>\n",
       "      <td>hackerrank - codewars - productivity - sql - p...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>Day 63 of  r2: started watching and watched th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_my_and_data_to</td>\n",
       "      <td>my - and - data - to - the - day - of - for - ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15716</th>\n",
       "      <td>Day 64 of  r2: watched the new video in the Ge...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_my_and_data_to</td>\n",
       "      <td>my - and - data - to - the - day - of - for - ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>Day 65 of  r2: spend some time working on the ...</td>\n",
       "      <td>308</td>\n",
       "      <td>308_tidytuesday_rstats_contribution_weeks</td>\n",
       "      <td>tidytuesday - rstats - contribution - weeks - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15768</th>\n",
       "      <td>In Round 2 I was mainly focused on:\\n- learnin...</td>\n",
       "      <td>50</td>\n",
       "      <td>50_machine_learning_ml_chapter</td>\n",
       "      <td>machine - learning - ml - chapter - python - p...</td>\n",
       "      <td>0.330318</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15769</th>\n",
       "      <td>Day 66 of  r2: on the final day I kept working...</td>\n",
       "      <td>308</td>\n",
       "      <td>308_tidytuesday_rstats_contribution_weeks</td>\n",
       "      <td>tidytuesday - rstats - contribution - weeks - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Document  Topic  \\\n",
       "83     Learning DS since January, now committing to :...     -1   \n",
       "198    Day 1 of : Today I worked on my stock analysis...    191   \n",
       "378    Day 2 of  : Today I made a lot of progress on ...    191   \n",
       "520    Day 3 of  : Today I learned about and implemen...     -1   \n",
       "680    Day 4 of , made an account on HackerRank, did ...    305   \n",
       "...                                                  ...    ...   \n",
       "15627  Day 63 of  r2: started watching and watched th...     -1   \n",
       "15716  Day 64 of  r2: watched the new video in the Ge...     -1   \n",
       "15744  Day 65 of  r2: spend some time working on the ...    308   \n",
       "15768  In Round 2 I was mainly focused on:\\n- learnin...     50   \n",
       "15769  Day 66 of  r2: on the final day I kept working...    308   \n",
       "\n",
       "                                            Name  \\\n",
       "83                             -1_my_and_data_to   \n",
       "198          191_trading_indicators_market_trade   \n",
       "378          191_trading_indicators_market_trade   \n",
       "520                            -1_my_and_data_to   \n",
       "680     305_hackerrank_codewars_productivity_sql   \n",
       "...                                          ...   \n",
       "15627                          -1_my_and_data_to   \n",
       "15716                          -1_my_and_data_to   \n",
       "15744  308_tidytuesday_rstats_contribution_weeks   \n",
       "15768             50_machine_learning_ml_chapter   \n",
       "15769  308_tidytuesday_rstats_contribution_weeks   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "83     my - and - data - to - the - day - of - for - ...     0.000000   \n",
       "198    trading - indicators - market - trade - system...     0.298689   \n",
       "378    trading - indicators - market - trade - system...     0.292834   \n",
       "520    my - and - data - to - the - day - of - for - ...     0.000000   \n",
       "680    hackerrank - codewars - productivity - sql - p...     1.000000   \n",
       "...                                                  ...          ...   \n",
       "15627  my - and - data - to - the - day - of - for - ...     0.000000   \n",
       "15716  my - and - data - to - the - day - of - for - ...     0.000000   \n",
       "15744  tidytuesday - rstats - contribution - weeks - ...     1.000000   \n",
       "15768  machine - learning - ml - chapter - python - p...     0.330318   \n",
       "15769  tidytuesday - rstats - contribution - weeks - ...     1.000000   \n",
       "\n",
       "       Representative_document  \n",
       "83                       False  \n",
       "198                      False  \n",
       "378                      False  \n",
       "520                      False  \n",
       "680                      False  \n",
       "...                        ...  \n",
       "15627                    False  \n",
       "15716                    False  \n",
       "15744                    False  \n",
       "15768                    False  \n",
       "15769                    False  \n",
       "\n",
       "[112 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df = topic_model.get_document_info(docs_no_mention)\n",
    "topic_df.iloc[filter_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Day 4 of , made an account on HackerRank, did the first problem solving tasks for Python and SQL.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[filter_idx].iloc[4][\"Document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x2e1412890>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reduce topics\n",
    "topic_model.reduce_topics(docs, nr_topics=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>14730</td>\n",
       "      <td>-1_of_66daysofdata_the_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11983</td>\n",
       "      <td>0_66daysofdata_of_the_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1831</td>\n",
       "      <td>1_pandas_numpy_day_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1074</td>\n",
       "      <td>2_statistics_logistic_regression_probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>957</td>\n",
       "      <td>3_visualization_matplotlib_plots_seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>928</td>\n",
       "      <td>4_sql_databases_joins_python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>823</td>\n",
       "      <td>5_tableau_linkedin_dashboard_on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>703</td>\n",
       "      <td>6_neural_deep_networks_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>7_linear_regression_algebra_pca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>685</td>\n",
       "      <td>8_web_scraping_javascript_portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>495</td>\n",
       "      <td>9_excel_pivot_sheets_spreadsheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>472</td>\n",
       "      <td>10_eda_de_dataset_en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>444</td>\n",
       "      <td>11_sports_sportsanalytics_our_nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>392</td>\n",
       "      <td>12_of66daysofdatacompleted_day_66daysofdata_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>365</td>\n",
       "      <td>13_azure_aws_cloud_microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>350</td>\n",
       "      <td>14_gradient_descent_validation_ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>321</td>\n",
       "      <td>15_100daysofcode_mlzoomcamp_algrigor_datatalks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>301</td>\n",
       "      <td>16_spark_series_pyspark_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>17_decision_random_tree_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>220</td>\n",
       "      <td>18_git_github_shell_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>168</td>\n",
       "      <td>19_titanic_kaggle_dataset_competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>164</td>\n",
       "      <td>20_testing_hypothesis_ab_pvalues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>148</td>\n",
       "      <td>21_covid19_covid_vaccine_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>22_pipelines_airflow_pipeline_leakage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>124</td>\n",
       "      <td>23_dashboard_dash_freelance_round4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>114</td>\n",
       "      <td>24_imbalanced_smote_fraud_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "      <td>25_tensorflow_tensors_tensor_gpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>111</td>\n",
       "      <td>26_jupyter_notebook_notebooks_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>105</td>\n",
       "      <td>27_tuning_hyperparameter_hyperparameters_grids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>94</td>\n",
       "      <td>28_django_flask_app_api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>29_correlation_covariance_coefficient_causation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>84</td>\n",
       "      <td>30_66daysofwellsleeping_slept_hours_leisurely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>31_geospatial_folium_geopandas_map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>70</td>\n",
       "      <td>32_xgboost_lightgbm_boosting_gradient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>33_scaling_preprocessing_normalization_standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>65</td>\n",
       "      <td>34_bioinformatics_molecular_drug_similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>35_docker_containers_devops_mlops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>36_womenwhocode_inovatesystems_womeninstem_wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>37_bias_fairness_variance_biasvariance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38_hackathon_team_working_participating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>39_heart_diabetes_disease_pima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>40_react_javascript_reactjs_js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>41_shap_shapley_values_explainability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>42_api_apis_fastapi_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>43_pycharm_code_pip_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>44_mimo_java_forgot_little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>45_weather_temperature_features_states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>46_iris_irisdataset_dataset_ocular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>47_monte_carlo_simulations_simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>48_ocr_pdf_files_pdfs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name\n",
       "0      -1  14730                         -1_of_66daysofdata_the_and\n",
       "1       0  11983                           0_66daysofdata_of_the_to\n",
       "2       1   1831                             1_pandas_numpy_day_and\n",
       "3       2   1074       2_statistics_logistic_regression_probability\n",
       "4       3    957           3_visualization_matplotlib_plots_seaborn\n",
       "5       4    928                       4_sql_databases_joins_python\n",
       "6       5    823                    5_tableau_linkedin_dashboard_on\n",
       "7       6    703                     6_neural_deep_networks_network\n",
       "8       7    700                    7_linear_regression_algebra_pca\n",
       "9       8    685                8_web_scraping_javascript_portfolio\n",
       "10      9    495                  9_excel_pivot_sheets_spreadsheets\n",
       "11     10    472                               10_eda_de_dataset_en\n",
       "12     11    444                  11_sports_sportsanalytics_our_nba\n",
       "13     12    392     12_of66daysofdatacompleted_day_66daysofdata_of\n",
       "14     13    365                       13_azure_aws_cloud_microsoft\n",
       "15     14    350               14_gradient_descent_validation_ridge\n",
       "16     15    321  15_100daysofcode_mlzoomcamp_algrigor_datatalks...\n",
       "17     16    301                       16_spark_series_pyspark_time\n",
       "18     17    247                     17_decision_random_tree_forest\n",
       "19     18    220                             18_git_github_shell_to\n",
       "20     19    168              19_titanic_kaggle_dataset_competition\n",
       "21     20    164                   20_testing_hypothesis_ab_pvalues\n",
       "22     21    148                      21_covid19_covid_vaccine_data\n",
       "23     22    136              22_pipelines_airflow_pipeline_leakage\n",
       "24     23    124                 23_dashboard_dash_freelance_round4\n",
       "25     24    114             24_imbalanced_smote_fraud_oversampling\n",
       "26     25    112                   25_tensorflow_tensors_tensor_gpu\n",
       "27     26    111                 26_jupyter_notebook_notebooks_code\n",
       "28     27    105  27_tuning_hyperparameter_hyperparameters_grids...\n",
       "29     28     94                            28_django_flask_app_api\n",
       "30     29     90    29_correlation_covariance_coefficient_causation\n",
       "31     30     84      30_66daysofwellsleeping_slept_hours_leisurely\n",
       "32     31     73                 31_geospatial_folium_geopandas_map\n",
       "33     32     70              32_xgboost_lightgbm_boosting_gradient\n",
       "34     33     68  33_scaling_preprocessing_normalization_standar...\n",
       "35     34     65        34_bioinformatics_molecular_drug_similarity\n",
       "36     35     46                  35_docker_containers_devops_mlops\n",
       "37     36     44  36_womenwhocode_inovatesystems_womeninstem_wom...\n",
       "38     37     40             37_bias_fairness_variance_biasvariance\n",
       "39     38     39            38_hackathon_team_working_participating\n",
       "40     39     32                     39_heart_diabetes_disease_pima\n",
       "41     40     28                     40_react_javascript_reactjs_js\n",
       "42     41     28              41_shap_shapley_values_explainability\n",
       "43     42     27                             42_api_apis_fastapi_to\n",
       "44     43     18                           43_pycharm_code_pip_used\n",
       "45     44     16                         44_mimo_java_forgot_little\n",
       "46     45     16             45_weather_temperature_features_states\n",
       "47     46     15                 46_iris_irisdataset_dataset_ocular\n",
       "48     47     14              47_monte_carlo_simulations_simulation\n",
       "49     48     11                              48_ocr_pdf_files_pdfs"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "e8ae99d9c20b736ed1ebdc5d0d4557145eaffa6a1bc0849b3635b3af9b7f0aff"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
